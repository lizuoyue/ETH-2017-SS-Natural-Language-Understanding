1. set data

export DATA_PATH=../../data

export VOCAB_SOURCE=${DATA_PATH}/source_vocab.txt
export VOCAB_TARGET=${DATA_PATH}/target_vocab.txt
export TRAIN_SOURCES=${DATA_PATH}/train/source.txt
export TRAIN_TARGETS=${DATA_PATH}/train/target.txt
export DEV_SOURCES=${DATA_PATH}/validation/source.txt
export DEV_TARGETS=${DATA_PATH}/validation/target.txt

export DEV_TARGETS_REF=${DATA_PATH}/validation/target.txt
export TRAIN_STEPS=1000000

2. configure .yml file

3. training

export MODEL_DIR=../model3
export CONFIG_PATH=../../ETH-2017-SS-Natural-Language-Understanding/yanping/config/baseline3.yml
export LOG_PATH=../log3.txt

mkdir -p $MODEL_DIR

nohup python3 -m bin.train \
  --config_paths="
      $CONFIG_PATH,
      ../../ETH-2017-SS-Natural-Language-Understanding/yanping/config/train_seq2seq.yml,
      ../../ETH-2017-SS-Natural-Language-Understanding/yanping/config/metrics.yml" \
  --model_params "
      vocab_source: $VOCAB_SOURCE
      vocab_target: $VOCAB_TARGET" \
  --input_pipeline_train "
    class: ParallelTextInputPipeline
    params:
      source_files:
        - $TRAIN_SOURCES
      target_files:
        - $TRAIN_TARGETS" \
  --input_pipeline_dev "
    class: ParallelTextInputPipeline
    params:
       source_files:
        - $DEV_SOURCES
       target_files:
        - $DEV_TARGETS" \
  --batch_size 64 \
  --train_steps $TRAIN_STEPS \
  --output_dir $MODEL_DIR > $LOG_PATH &

  4. to-do
  beam search?
  